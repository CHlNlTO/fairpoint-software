16-07-2025 - Page 1
Patent Translate
Powered by EPO and Google
Notice
This translation is machine-generated. It cannot be guaranteed that it is intelligible, accurate,
complete, reliable or fit for specific purposes. Critical decisions, such as commercially
relevant or financial decisions, should not be based on machine-translation output.
DESCRIPTION CN110958475A
A cross-device content projection method and electronic device
[0001]
Technical Field
[0002]
The present application relates to the field of terminals, and in particular to a cross-device
content projection method and an electronic device.
[0003]
Background Art
[0004]
With the development of smart terminal technology, a user or a family often has multiple
electronic devices, and the user often needs to switch between the multiple electronic
devices.
For example, a user watches a video on a mobile phone and may want to switch the video to
the TV to continue watching after returning home.
For another example, a user may use a laptop computer to work at home, and when the user
leaves home, he or she may want to switch files in the laptop computer to a mobile phone to
continue working.
[0005]
16-07-2025 - Page 2
In this cross-device interaction scenario, users are usually required to manually project
content from one device to another or more devices.
For example, users can connect mobile phones, smart TVs, speakers and other electronic
devices to the same Wi-Fi network. When users need to project content in their mobile
phones to other electronic devices, they can use the screen projection function in their
mobile phones or screen projection software to search for multiple electronic devices in the
current Wi-Fi network.
Furthermore, the user may select a target device to receive the projection content this time
from among the multiple electronic devices searched. In this way, the mobile phone can
project pictures, videos, audio and other content to the target device through the Wi-Fi
network. Obviously, this process of switching projection content between multiple devices is
time-consuming and cumbersome, and the user experience is not good.
[0006]
Summary of the invention
[0007]
The present application provides a cross-device content projection method and an electronic
device, whereby the electronic device can conveniently and quickly project the projection
content to multiple other electronic devices for playback, thereby improving the
collaborative work efficiency between multiple devices during content projection.
[0008]
In order to achieve the above purpose, this application adopts the following technical
solutions:
[0009]
In a first aspect, the present application provides a cross-device content projection method,
including: a first electronic device starts playing a first content, for example, the first content
may include display content and/or audio content; then, when the distance between the first
electronic device and the NFC tag is close enough, the first electronic device can obtain N (N
is an integer greater than 1) second electronic devices bound to the NFC tag from the NFC
tag; in this way, the first electronic device can project the first content to at least one of the N
second electronic devices according to a preset projection strategy to continue playing.
[0010]
16-07-2025 - Page 3
That is to say, by reading the second electronic device bound to the NFC tag, the first
electronic device can easily and quickly determine the multiple target devices for this content
projection, and automatically start projecting the projection content to the multiple target
devices, which simplifies the user's operation process when projecting content across
devices, improves and enriches the user's experience, and at the same time improves the
work efficiency of collaboration between multiple devices during content projection.
[0011]
The first content projected by the first electronic device to the second electronic device may
include part or all of the display content currently displayed in the display interface of the
first electronic device.
For example, the first electronic device may project all displayed content in the first interface
(eg, desktop) being displayed as first content to the second electronic device.
For another example, the first electronic device may project an image in a video in a playback
interface being displayed as the first content to the second electronic device.
[0012]
Alternatively, the first content projected by the first electronic device to the second electronic
device may also include audio content being played by the first electronic device, such as
music being played by the first electronic device or audio being played in synchronization
with a video.
Of course, after the first electronic device projects the first content to the second electronic
device, if the first electronic device starts playing other content (such as the second content)
in response to a user operation, the first electronic device can continue to project the second
content to the second electronic device for playback.
[0013]
In one possible implementation, a first electronic device obtains N second electronic devices
bound to an NFC tag from an NFC tag, including: in response to a tap operation in which the
first electronic device approaches or contacts the NFC tag, the first electronic device reads
the identifiers of the N second electronic devices stored in the NFC tag to determine the N
second electronic devices bound to the NFC tag; or, after the first electronic device detects
an NFC signal from the NFC tag using an NFC chip of the first electronic device, the first
electronic device reads the identifiers of the N second electronic devices stored in the NFC
tag through the NFC signal to determine the N second electronic devices bound to the NFC
tag.
16-07-2025 - Page 4
[0014]
That is to say, the user can trigger the first electronic device to read the identifier of the
second electronic device stored in the NFC tag through the NFC function by approaching or
touching the NFC tag, thereby determining the N second electronic devices that are
projecting content with the first electronic device this time.
[0015]
In a possible implementation, the first electronic device projects the first content to at least
one of the N second electronic devices for continued playback according to a preset
projection strategy, including: the first electronic device sends the first content to at least
one of the N second electronic devices for playback according to a preset projection strategy.
That is to say, the first electronic device can be used as the main device for content
projection this time to control the second electronic device to project the content.
[0016]
Exemplarily, the N second electronic devices may include a first speaker and a second
speaker; wherein the first electronic device sends the first content to at least one of the N
second electronic devices for playback according to a preset projection strategy, including:
the first electronic device sends the first content to the first speaker for playback, and the
first speaker is the speaker closest to the first electronic device; or, the first electronic device
sends the first content to the first speaker and the second speaker for playback.
[0017]
For example, the first electronic device may compare the distance between itself and the first
speaker and the second speaker.
If the distance between the first speaker and the first electronic device is less than a preset
value, and the distance between the second speaker and the first electronic device is greater
than a preset value, it means that the first speaker is closer to the first electronic device and
the second speaker is farther away from the first electronic device. In this case, the first
electronic device can send the first content to the first speaker for playback to complete the
content projection.
[0018]
For another example, if the distance between the first speaker and the first electronic device
is less than a preset value, and the distance between the second speaker and the first
16-07-2025 - Page 5
electronic device is also less than the preset value, it means that the first speaker and the
second speaker are very close to the first electronic device. The first electronic device can
send the first content to both the first speaker and the second speaker, thereby projecting
the first content to the first speaker and the second speaker for playback.
Of course, the first electronic device may also determine, based on the stored projection
strategy, to which specific device or devices the first content is to be sent for playback, and
the embodiment of the present application does not impose any limitation on this.
[0019]
In one possible implementation, the first electronic device sends the first content to the first
speaker and the second speaker for playback, including: the first electronic device sends the
first audio component in the first content to the first speaker for playback; and the first
electronic device sends the second audio component in the first content to the second
speaker for playback.
Of course, if the N second electronic devices further include a third speaker, the mobile
phone can send the third audio component in the first content to the third speaker for
playback.
That is to say, the first electronic device can send the corresponding audio component in the
projected content to each speaker, so that multiple speakers play the received audio
components respectively to achieve stereo or surround sound playback effects.
[0020]
In one possible implementation, the N second electronic devices may include a speaker
(there may be one or more speakers) and a television (there may be one or more televisions);
wherein the first electronic device sends the first content to at least one of the N second
electronic devices for playback according to a preset projection strategy, including: the first
electronic device may send the display content (such as an image or video) in the first
content to the television for playback; and the first electronic device sends the audio content
in the first content to the speaker for playback; or, the first electronic device may send the
display content in the first content to the television for playback; and the first electronic
device sends the audio content in the first content to the television and the speaker for
playback.
[0021]
In a possible implementation, after the first electronic device obtains N second electronic
devices bound to the NFC tag from the NFC tag, it also includes: the first electronic device
16-07-2025 - Page 6
determines a master device among the N second electronic devices; wherein the first
electronic device projects the first content to at least one second electronic device among
the N second electronic devices according to a preset projection strategy for continued
playback, including: the first electronic device sends the first content to the master device, so
that the master device controls at least one second electronic device among the N second
electronic devices to play the first content according to the preset projection strategy.
That is to say, the first electronic device may determine a master device among the N second
electronic devices, and the master device controls the N second electronic devices to realize
the current content projection.
[0022]
Exemplarily, the N second electronic devices mentioned above may include a television and a
lamp; wherein the first electronic device determines the main device among the N second
electronic devices, including: the first electronic device determines the television as the main
device among the N second electronic devices mentioned above; at this time, the preset
projection control strategy may include: the television plays the display content and audio
content in the first content, and the television sends control instructions to the lamp
according to the first content to control the brightness or color of the lamp to achieve
different lamp effects.
[0023]
In a possible implementation manner, after the first electronic device determines the master
device among the N second electronic devices, the method further includes: the first
electronic device sending the stored projection strategy to the master device.
Of course, the main device can also obtain the above projection strategy from other
electronic devices or servers.
[0024]
In a possible implementation, before the first electronic device projects the first content to at
least one of N second electronic devices according to a preset projection strategy for
continued playback, the process further includes: the first electronic device performs time
synchronization with the N second electronic devices; wherein the first content sent by the
first electronic device carries a timestamp, and the timestamp is used to indicate the
playback progress of the first content.
Since the time of each device is synchronized after the first electronic device is synchronized
with the N second electronic devices, when the second electronic device plays the projected
16-07-2025 - Page 7
content according to the timestamp in the first content, the playback progress of each
second electronic device can be guaranteed to be the same.
[0025]
In a possible implementation, after the first electronic device obtains N second electronic
devices bound to the NFC tag from the NFC tag, the method further includes: the first
electronic device receives projection strategies input by a user for the N second electronic
devices.
That is to say, the user can manually set corresponding projection strategies for multiple
devices participating in content projection during the content projection process.
[0026]
In a second aspect, the present application provides a cross-device content projection
method, including: a first electronic device displays a binding interface of an NFC tag, the
binding interface including a list of candidate devices waiting to be bound to the NFC tag, the
candidate devices in the candidate device list and the first electronic device being located in
the same communication network; if the first electronic device detects a first operation of a
user selecting M (M is an integer greater than 0) second electronic devices in the above-
mentioned candidate device list, then in response to the first operation, the first electronic
device may prompt the user to bring the first electronic device close to or into contact with
the above-mentioned NFC tag, so that the first electronic device can write the identifications
of the above-mentioned M second electronic devices into the NFC tag to establish a binding
relationship between the NFC tag and the M second electronic devices.
[0027]
In this way, when the first electronic device needs to perform content projection later, it can
determine one or more second electronic devices bound to the NFC tag, that is, the target
devices for content projection, by reading the identifier of the bound device in the NFC tag.
[0028]
In one possible implementation, the first electronic device displays the binding interface of
the NFC tag, including: the first electronic device reads a preset flag bit in the NFC tag; if the
value in the flag bit is a first preset value, it means that the NFC tag has not been bound to
any electronic device, and the first electronic device can open a preset projection application
to display the binding interface of the NFC tag.
16-07-2025 - Page 8
[0029]
In a possible implementation, after the first electronic device writes the identifiers of the M
second electronic devices into the NFC tag, the process further includes: the first electronic
device modifies the value of the flag bit from a first preset value to a second preset value,
thereby indicating that the NFC tag has been bound to one or more electronic devices.
[0030]
In a possible implementation, after the first electronic device writes the identifiers of the M
second electronic devices into the NFC tag, it also includes: the first electronic device displays
a setting interface for the projection strategy; the first electronic device receives the
projection strategy input by the user for the M second electronic devices in the setting
interface, and saves the projection strategy.
That is, after the first electronic device establishes the corresponding binding relationship in
the NFC tag, the user can continue to set the projection strategy of the M second electronic
devices bound to the NFC tag when performing content projection in the projection
application.
[0031]
For example, when M=1, the projection strategy may include a correspondence between
different NFC operations and projection instructions.
For example, touching the NFC tag once corresponds to projection instruction 1; touching
the NFC tag twice corresponds to projection instruction 2.
[0032]
For another example, when M>1, the projection strategy may include content projection
rules set for each second electronic device.
For example, the M second electronic devices include a television, a speaker, and a lamp, and
the user can set specific projection rules for projecting to the television, the speaker, and the
lamp respectively in the setting interface.
[0033]
Exemplarily, when the M second electronic devices include a first speaker and a second
speaker, the projection strategy may be: using the speaker closest to the source device to
16-07-2025 - Page 9
play the projection content, or the projection strategy may be: using the first speaker to play
the first audio component in the projection content and using the second speaker to play the
second audio component in the projection content;
[0034]
For another example, when the M second electronic devices include a television and a
speaker, the projection strategy may be: using the television to play the display content in
the projection content, and using the speaker to play the audio content in the projection
content; or using the television to play the display content in the projection content, and
using the speaker and the television to play the audio content in the projection content;
[0035]
For another example, when the M second electronic devices include a television and a lamp,
the projection strategy is: using the television to play the projection content, and the
television to control the lighting effect of the lamp.
[0036]
In a possible implementation, after the first electronic device writes the identifiers of the M
second electronic devices into the NFC tag, the method further includes: the first electronic
device sends the binding relationship between the NFC tag and the M second electronic
devices to other electronic devices or a server.
In this way, the first electronic device can share the binding relationship with other electronic
devices for use, or the user can also obtain the binding relationship when logging into the
server using other electronic devices.
[0037]
Exemplarily, the candidate devices in the candidate device list and the first electronic device
may be located in the same Wi-Fi network, or the candidate devices in the candidate device
list and the first electronic device may be bound to the same account.
[0038]
Exemplarily, the first electronic device writes the identifier of the second electronic device
into the NFC tag, including: in response to a tap operation in which the first electronic device
approaches or contacts the NFC tag, the first electronic device writes the identifier of the
16-07-2025 - Page 10
second electronic device into the NFC tag; or, after the first electronic device detects an NFC
signal from the NFC tag using its NFC chip, the first electronic device may write the identifier
of the second electronic device into the NFC tag.
That is, the user can trigger the first electronic device to write the identifier of the second
electronic device into the NFC tag by approaching or touching the NFC tag.
[0039]
Similarly, the first electronic device reads a preset flag bit in the NFC tag, including: in
response to a tap operation in which the first electronic device approaches or contacts the
NFC tag, the first electronic device can read the preset flag bit in the NFC tag; or, after the
first electronic device uses its NFC chip to detect an NFC signal from the NFC tag, it can read
the preset flag bit in the NFC tag.
That is to say, the user can trigger the first electronic device to read the preset flag bit in the
NFC tag by approaching or touching the NFC tag.
[0040]
In a third aspect, the present application provides a content projection system, comprising a
first electronic device, N second electronic devices and an NFC tag, where N is an integer
greater than 1; the NFC tag stores a binding relationship between the NFC tag and the above-
mentioned N second electronic devices; wherein the first electronic device is used to execute
any of the above-mentioned cross-device content projection methods.
[0041]
In a possible implementation, the N second electronic devices include a master device,
wherein the master device is used to: receive first content sent by a first electronic device;
and control at least one second electronic device among the N second electronic devices to
play the first content according to a preset projection strategy.
Alternatively, the first electronic device may serve as a master device and control at least one
of the N second electronic devices to play the first content according to a preset projection
strategy.
[0042]
In a fourth aspect, the present application provides an electronic device, comprising: a touch
screen, a communication interface, one or more processors, a memory, and one or more
computer programs; wherein the processor is coupled to the touch screen, the
communication interface, and the memory, and the one or more computer programs are
16-07-2025 - Page 11
stored in the memory, and when the electronic device is running, the processor executes the
one or more computer programs stored in the memory so that the electronic device
executes any of the cross-device content projection methods described above.
[0043]
In a fifth aspect, the present application provides a computer storage medium, including
computer instructions, which, when executed on an electronic device, enables the electronic
device to execute any one of the above-described cross-device content projection methods.
[0044]
In a sixth aspect, the present application provides a computer program product, which,
when executed on an electronic device, enables the electronic device to execute any one of
the above-described cross-device content projection methods.
[0045]
It can be understood that the content projection system described in the third aspect, the
electronic device described in the fourth aspect, the computer-readable storage medium
described in the fifth aspect, and the computer program product described in the sixth
aspect are all used to execute the corresponding methods provided above. Therefore, the
beneficial effects that can be achieved can refer to the beneficial effects in the corresponding
methods provided above, and will not be repeated here.
[0046]
BRIEF DESCRIPTION OF THE DRAWINGS
[0047]
FIG1 is a schematic diagram of an architecture of a content projection system provided by an
embodiment of the present application;
[0048]
FIG. 2 is a second schematic diagram of the architecture of a content projection system
provided by an embodiment of the present application;
[0049]
16-07-2025 - Page 12
FIG3 is a third schematic diagram of the architecture of a content projection system provided
by an embodiment of the present application;
[0050]
FIG4 is a fourth schematic diagram of the architecture of a content projection system
provided in an embodiment of the present application;
[0051]
FIG5 is a first structural diagram of an electronic device provided in an embodiment of the
present application;
[0052]
FIG6 is a schematic diagram of the architecture of an operating system in an electronic
device provided in an embodiment of the present application;
[0053]
FIG. 7 is a schematic diagram of an application scenario of a cross-device content projection
method provided by an embodiment of the present application;
[0054]
FIG8 is a flowchart diagram 1 of a cross-device content projection method provided by an
embodiment of the present application;
[0055]
FIG9 is a second schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0056]
FIG10 is a third schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0057]
FIG. 11 is a fourth schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
16-07-2025 - Page 13
[0058]
FIG12 is a fifth schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0059]
FIG13 is a sixth schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0060]
FIG. 14 is a seventh schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0061]
FIG15 is a schematic diagram of an application scenario eight of a cross-device content
projection method provided by an embodiment of the present application;
[0062]
FIG. 16 is a second flow chart of a cross-device content projection method provided in an
embodiment of the present application;
[0063]
FIG. 17 is a ninth schematic diagram of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0064]
FIG. 18 is a schematic diagram of an application scenario of a cross-device content projection
method provided by an embodiment of the present application;
[0065]
FIG. 19 is a schematic diagram eleven of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0066]
16-07-2025 - Page 14
FIG. 20 is a schematic diagram twelfth of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0067]
FIG. 21 is a schematic diagram thirteen of an application scenario of a cross-device content
projection method provided by an embodiment of the present application;
[0068]
FIG. 22 is a second structural schematic diagram of an electronic device provided in an
embodiment of the present application.
[0069]
DETAILED DESCRIPTION
[0070]
The implementation of this embodiment will be described in detail below with reference to
the accompanying drawings.
[0071]
A cross-device content projection method provided in an embodiment of the present
application may be applied to a communication system (also referred to as a content
projection system) 100 shown in FIG. 1 .
As shown in FIG. 1 , the communication system 100 may include N (N is an integer greater
than 1) electronic devices.
These N electronic devices can be interconnected via a communication network.
[0072]
Exemplarily, the above communication network may be a wired network or a wireless
network.
For example, the communication network may be a local area network (LAN) or a wide area
network (WAN), such as the Internet.
The above-mentioned communication network can be implemented using any known
network communication protocol, and the above-mentioned network communication
protocol can be various wired or wireless communication protocols, such as Ethernet,
universal serial bus (USB), FIREWIRE, global system for mobile communications (GSM),
16-07-2025 - Page 15
general packet radio service (GPRS), code division multiple access (CDMA), wideband code
division multiple access (WCDMA), time division code division multiple access (TD-SCDMA),
long term evolution (LTE), Bluetooth, wireless fidelity (Wi-Fi), NFC, voice over Internet
protocol (VoIP), communication protocols supporting network slicing architecture or any
other suitable communication protocols.
[0073]
For example, in some embodiments, a Wi-Fi connection may be established between various
electronic devices in the communication system 100 via a Wi-Fi protocol.
In other embodiments, each electronic device in the communication system 100 can be
interconnected through one or more servers after logging into the same account (such as a
Huawei account).
[0074]
Exemplarily, the communication system 100 may include a first electronic device 101 and a
second electronic device 102 .
For example, as shown in (a) of FIG. 2 , the first electronic device 101 may serve as a source
device, and the second electronic device 102 may serve as a target device of the first
electronic device 101 .
The electronic device 101 may project the displayed or played content to the second
electronic device 102 .
In subsequent embodiments, the specific content projected from one electronic device to
another electronic device may be referred to as projected content. For example, the
projected content may include text, pictures, videos, audio, animations, lighting effects, or
web pages.
For example, an electronic device may send projection content such as text, pictures, videos,
audio, animations or web pages to another electronic device for display or playback;
alternatively, an electronic device may send light control instructions as projection content to
another electronic device, thereby controlling the light to produce corresponding lighting
effects.
[0075]
In some embodiments, the first electronic device 101 may have multiple target devices.
For example, the communication system 100 may further include a third electronic device
in addition to the first electronic device 101 and the second electronic device 102 .
16-07-2025 - Page 16
As shown in (b) of FIG. 2 , when the first electronic device 101 is a source device, the second
electronic device 102 and the third electronic device 103 can both serve as target devices of
the first electronic device 101 to receive the projection content sent by the first electronic
device 101 .
In this way, the first electronic device 101 can simultaneously project the projection content
to multiple electronic devices for display or playback.
For example, a mobile phone can cast its audio files to multiple speakers at the same time.
For another example, the mobile phone can project the displayed video screen to the TV for
display, and at the same time project the audio content corresponding to the video screen to
the speaker for playback.
[0076]
That is, the source device in the communication system 100 can project the projection
content to one or more target devices, thereby achieving cross-device interaction when
content is projected between multiple devices.
[0077]
In the embodiment of the present application, an electronic tag bound to one or more
electronic devices may also be provided in the communication system 100, which may also
be referred to as a radio frequency tag or RFID (radio frequency identification) tag.
Electronic devices can read the information stored in electronic tags by sending radio
frequency signals.
[0078]
To facilitate understanding by those skilled in the art, the working principle of the electronic
tag is introduced in the embodiment of the present application.
[0079]
Exemplarily, the electronic tag may include three implementation forms, namely: a passive
tag, a semi-active tag and an active tag.
In the embodiment of the present application, the electronic tag may be any one of a passive
tag, a semi-active tag or an active tag.
[0080]
(1) Passive tag: When the electronic tag is a passive tag, there is no internal power supply in
the electronic tag.
16-07-2025 - Page 17
When the electronic tag is close to the NFC (near field communication) chip of other devices,
it can receive the electromagnetic wave information sent by the NFC chip of other devices.
At this time, the internal integrated circuit (IC) of the electronic tag is driven by the received
electromagnetic wave signal.
When the electronic tag receives an electromagnetic wave signal of sufficient strength, it can
send the data stored in the electronic tag to the NFC chip of other devices, such as the device
information of the above-mentioned laptop.
[0081]
(2) Semi-active tags: The working mode of semi-active tags is similar to that of passive tags.
When the electronic tag is a semi-active tag, the electronic tag includes a small battery, and
the power of the small battery is sufficient to drive the internal IC of the electronic tag so
that the IC is in a working state.
Since the semi-active tag includes the small battery mentioned above, the semi-active tag
has a faster response speed than the passive tag.
[0082]
(3) Active tag: When the electronic tag is an active tag, it includes an internal power supply to
supply the power required by the internal IC to generate external signals.
Generally speaking, active tags allow radio frequency communication over longer distances,
and active tags have larger storage space that can be used to store data transmitted from
NFC chips of other devices.
[0083]
As shown in FIG. 3 , the electronic tag may specifically be an NFC tag 301 implemented using
NFC technology (the NFC tag may also be referred to as an NFC patch).
When the NFC chip in an electronic device (such as a mobile phone) is in contact with or close
to the NFC tag 301, the NFC chip in the mobile phone can detect the NFC signal emitted by
the NFC tag 301, and then read the information stored in the NFC tag 301 through the NFC
signal.
That is, the mobile phone can respond to a tap operation of approaching or contacting the
NFC tag 301 and obtain the information stored in the NFC tag 301 from the NFC tag 301 .
[0084]
Exemplarily, the NFC tag 301 is generally provided with a coil, and the binding relationship
between the NFC tag 301 and one or more electronic devices can be stored through the coil.
16-07-2025 - Page 18
An electronic device can be bound to one or more NFC tags 301 .
For example, each NFC tag 301 uniquely corresponds to an NFC card number, so the NFC
card number and the identifier of the electronic device A can be written into the coil of the
NFC tag 301 in advance, thereby establishing a binding relationship between the NFC tag
and the electronic device A in the NFC tag 301 .
[0085]
It is understandable that the binding relationship stored in the NFC tag 301 can be pre-set
when the NFC tag 301 leaves the factory, or can be manually set by the user when using (for
example, using for the first time) the NFC tag 301, and the embodiment of the present
application does not impose any limitation on this.
[0086]
Taking the example of binding the NFC tag 301 with the TV (also called a smart TV) in the
communication system 100, as shown in Figure 3, when the user needs to project the
content displayed or played in the source device (such as a mobile phone) as projection
content to the smart TV (i.e., the target device), the user can turn on the NFC function of the
mobile phone and approach or touch the NFC tag 301.
When the distance between the mobile phone and the NFC tag 301 is close enough, the
mobile phone can read the binding relationship between the NFC tag 301 and the smart TV
from the NFC tag 301 by transmitting a near field signal.
For example, the mobile phone can read the identification of the smart TV from the NFC tag
301 .
The identifier may be a MAC (media access control) address, a device name, or an IP address
of the smart TV.
[0087]
That is to say, the mobile phone can determine that the target device for content projection
this time is the smart TV by reading the above binding relationship.
Then, the mobile phone, as a source device, can start sending the projection content to the
smart TV according to the read identifier of the smart TV, so that the smart TV can display or
play the projection content as a target device, completing the content projection process.
[0088]
16-07-2025 - Page 19
The above-mentioned TV (or smart TV) may be an analog TV that works using analog signals,
or a digital TV that works using digital signals, or any display output device that can play
images, audio or video.
In some scenarios, the above-mentioned TV (or smart TV) may also be referred to as a smart
screen or a large-screen device.
[0089]
In some embodiments, the NFC tag 301 may record the binding relationship between the
NFC tag 301 and multiple electronic devices.
For example, the NFC tag 301 can be bound to both a smart TV and a speaker (also referred
to as a smart speaker).
Then, as shown in FIG. 4 , when the user turns on the NFC function of the mobile phone and
approaches or touches the NFC tag 301 , the logos of the smart TV and the smart speaker
can be read, indicating that the user wants to project the content in the mobile phone to the
smart TV and the smart speaker this time.
Furthermore, the mobile phone can project the display content in the projection content to
the smart TV for display according to the preset strategy, and project the audio content in
the projection content to the smart speaker for playback, thereby completing the content
projection process.
[0090]
It can be seen that by using the method of "touching" the source device with the NFC tag,
the source device can easily and quickly determine the target device for this content
projection, and then automatically start projecting the projection content to the target
device, which simplifies the user's operation process when projecting content across devices,
improves and enriches the user's experience, and at the same time improves the work
efficiency of collaboration between multiple devices during content projection.
[0091]
Exemplarily, the electronic device in the above-mentioned communication system 100 can be
a mobile phone, a tablet computer, a television, a laptop computer, a smart home device, a
wearable electronic device, a vehicle-mounted device, a virtual reality device, etc., and the
embodiments of the present application do not impose any restrictions on this.
Among them, smart home devices can specifically be: TV, speakers, air conditioners (also
called smart air conditioners), refrigerators (also called smart refrigerators), lights (also
called smart lights or smart bulbs) or curtains (also called smart curtains), etc.
16-07-2025 - Page 20
[0092]
Taking a mobile phone as an example of the above electronic device, FIG5 shows a
schematic structural diagram of the mobile phone.
[0093]
The mobile phone may include a processor 110, an external memory interface 120, an
internal memory 121, a universal serial bus (USB) interface 130, an antenna 1, an antenna 2,
a mobile communication module 150, a wireless communication module 160, an audio
module 170, a speaker 170A, a receiver 170B, a microphone 170C, an earphone interface
170D, a sensor module 180, etc.
[0094]
It is understandable that the structure illustrated in the embodiment of the present
invention does not constitute a specific limitation on the mobile phone.
In other embodiments of the present application, the mobile phone may include more or
fewer components than those shown in the figure, or combine some components, or
separate some components, or arrange the components differently.
The components shown in the figures may be implemented in hardware, software or a
combination of software and hardware.
[0095]
The processor 110 may include one or more processing units. For example, the processor
110 may include an application processor (AP), a modem processor, a graphics processor
(GPU), an image signal processor (ISP), a controller, a memory, a video codec, a digital signal
processor (DSP), a baseband processor, and/or a neural-network processing unit (NPU), etc.
Among them, different processing units can be independent devices or integrated into one
or more processors.
[0096]
The processor 110 may also be provided with a memory for storing instructions and data.
In some embodiments, the memory in processor 110 is a cache memory.
The memory may store instructions or data that the processor 110 has just used or is
recycling.
If the processor 110 needs to use the instruction or data again, it can be directly called from
the memory.
16-07-2025 - Page 21
Repeated access is avoided, the waiting time of the processor 110 is reduced, and the
efficiency of the system is improved.
[0097]
In some embodiments, processor 110 may include one or more interfaces.
The interface may include an inter-integrated circuit (I2C) interface, an inter-integrated
circuit sound (I2S) interface, a pulse code modulation (PCM) interface, a universal
asynchronous receiver/transmitter (UART) interface, a mobile industry processor interface
(MIPI), a general-purpose input/output (GPIO) interface, a subscriber identity module (SIM)
interface, and/or a universal serial bus (USB) interface, etc.
[0098]
The wireless communication function of the mobile phone can be realized through antenna
1, antenna 2, mobile communication module 150, wireless communication module 160,
modem processor and baseband processor.
[0099]
Antenna 1 and antenna 2 are used to transmit and receive electromagnetic wave signals.
Each antenna in a mobile phone can be used to cover a single or multiple communication
frequency bands.
Different antennas can also be reused to improve antenna utilization.
For example, antenna 1 may be reused as a diversity antenna for a wireless local area
network.
In other embodiments, the antenna may be used in conjunction with a tuning switch.
[0100]
The mobile communication module 150 can provide wireless communication solutions
including 2G/3G/4G/5G etc. applied on mobile phones.
The mobile communication module 150 may include at least one filter, a switch, a power
amplifier, a low noise amplifier (LNA), etc.
The mobile communication module 150 can receive electromagnetic waves through the
antenna 1, filter, amplify and process the received electromagnetic waves, and transmit
them to the modem processor for demodulation.
The mobile communication module 150 can also amplify the signal modulated by the
modem processor and convert it into electromagnetic waves for radiation through the
antenna 1.
16-07-2025 - Page 22
In some embodiments, at least some functional modules of the mobile communication
module 150 may be set in the processor 110 .
In some embodiments, at least some functional modules of the mobile communication
module 150 and at least some modules of the processor 110 may be provided in the same
device.
[0101]
The wireless communication module 160 can provide wireless communication solutions for
use on mobile phones, including wireless local area networks (WLAN) (such as wireless
fidelity (Wi-Fi) networks), Bluetooth (BT), global navigation satellite system (GNSS), frequency
modulation (FM), near field communication technology (NFC), infrared technology (IR), etc.
The wireless communication module 160 may be one or more devices integrating at least
one communication processing module.
The wireless communication module 160 receives electromagnetic waves via the antenna 2 ,
modulates and filters the electromagnetic wave signals, and sends the processed signals to
the processor 110 .
The wireless communication module 160 can also receive the signal to be sent from the
processor 110, modulate the frequency of the signal, amplify the signal, and convert it into
electromagnetic waves for radiation through the antenna 2.
[0102]
In some embodiments, the mobile phone's antenna 1 is coupled to the mobile
communication module 150, and the antenna 2 is coupled to the wireless communication
module 160, so that the mobile phone can communicate with the network and other devices
through wireless communication technology.
The wireless communication technology may include global system for mobile
communications (GSM), general packet radio service (GPRS), code division multiple access
(CDMA), wideband code division multiple access (WCDMA), time-division code division
multiple access (TD-SCDMA), long term evolution (LTE), BT, GNSS, WLAN, NFC, FM, and/or IR
technology, etc.
The GNSS may include a global positioning system (GPS), a global navigation satellite system
(GLONASS), a Beidou navigation satellite system (BDS), a quasi-zenith satellite system (QZSS)
and/or a satellite based augmentation system (SBAS).
[0103]
16-07-2025 - Page 23
The mobile phone realizes display functions through GPU, display screen 194, and
application processor.
The GPU is a microprocessor for image processing, which connects the display screen 194
and the application processor.
The GPU is used to perform mathematical and geometric calculations for graphics rendering.
Processor 110 may include one or more GPUs that execute program instructions to generate
or change display information.
[0104]
Display screen 194 is used to display images, videos, etc.
Display screen 194 includes a display panel.
The display panel can adopt liquid crystal display (LCD), organic light-emitting diode (OLED),
active matrix organic light emitting diode or active matrix organic light emitting diode
(AMOLED), flexible light emitting diode (FLED), Miniled, MicroLed, Micro-oLed, quantum dot
light-emitting diodes (QLED), etc.
In some embodiments, the mobile phone may include 1 or N display screens 194 , where N is
a positive integer greater than 1.
[0105]
The mobile phone can realize the shooting function through ISP, camera 193, video codec,
GPU, display 194 and application processor.
[0106]
The ISP is used to process data fed back by the camera 193 .
For example, when taking a photo, the shutter is opened, and light is transmitted through
the lens to the camera's photosensitive element. The light signal is converted into an
electrical signal, and the camera's photosensitive element transmits the electrical signal to
the ISP for processing and converts it into an image visible to the naked eye.
ISP can also perform algorithm optimization on image noise, brightness, and skin color.
ISP can also optimize the exposure, color temperature and other parameters of the shooting
scene.
In some embodiments, the ISP may be provided in the camera 193 .
[0107]
The camera 193 is used to capture still images or videos.
16-07-2025 - Page 24
The object generates an optical image through the lens and projects it onto the
photosensitive element.
The photosensitive element can be a charge coupled device (CCD) or a complementary metal-
oxide-semiconductor (CMOS) phototransistor.
The photosensitive element converts the light signal into an electrical signal, which is then
transmitted to the ISP for conversion into a digital image signal.
ISP outputs the digital image signal to DSP for processing.
DSP converts digital image signals into standard image signals in RGB, YUV and other
formats.
In some embodiments, the mobile phone may include 1 or N cameras 193 , where N is a
positive integer greater than 1.
[0108]
Digital signal processors are used to process digital signals. In addition to processing digital
image signals, they can also process other digital signals.
For example, when the mobile phone selects a frequency point, the digital signal processor is
used to perform Fourier transform on the frequency point energy.
[0109]
Video codecs are used to compress or decompress digital video.
A phone may support one or more video codecs.
In this way, the mobile phone can play or record videos in multiple encoding formats, such
as: Moving Picture Experts Group (MPEG) 1, MPEG2, MPEG3, MPEG4, etc.
[0110]
The external memory interface 120 can be used to connect an external memory card, such
as a Micro SD card, to expand the storage capacity of the mobile phone.
The external memory card communicates with the processor 110 via the external memory
interface 120 to implement a data storage function.
For example, save music, videos and other files in an external storage card.
[0111]
The internal memory 121 may be used to store computer executable program codes,
wherein the executable program codes include instructions.
The processor 110 executes instructions stored in the internal memory 121 to perform
various functional applications and data processing of the mobile phone.
16-07-2025 - Page 25
The internal memory 121 may include a program storage area and a data storage area.
The program storage area may store an operating system, an application program required
for at least one function (such as a sound playback function, an image playback function,
etc.), and the like.
The storage data area can store data created during the use of the mobile phone (such as
audio data, phone book, etc.).
In addition, the internal memory 121 may include a high-speed random access memory and
may also include a non-volatile memory, such as at least one disk storage device, a flash
memory device, a universal flash storage (UFS), etc.
[0112]
The mobile phone can implement audio functions through the audio module 170, the
speaker 170A, the receiver 170B, the microphone 170C, the earphone interface 170D, and
the application processor.
Such as music playing, recording, etc.
[0113]
The audio module 170 is used to convert digital audio information into analog audio signal
output, and is also used to convert analog audio input into digital audio signals.
The audio module 170 may also be used to encode and decode audio signals.
In some embodiments, the audio module 170 may be disposed in the processor 110 , or
some functional modules of the audio module 170 may be disposed in the processor 110 .
[0114]
The speaker 170A, also called a "horn", is used to convert audio electrical signals into sound
signals.
The mobile phone can listen to music through the speaker 170A, or listen to hands-free calls.
[0115]
The receiver 170B, also called a "handset", is used to convert audio electrical signals into
sound signals.
When the mobile phone receives a call or voice message, the voice can be heard by placing
the receiver 170B close to the human ear.
[0116]
16-07-2025 - Page 26
Microphone 170C, also called "microphone" or "microphone", is used to convert sound
signals into electrical signals.
When making a call or sending a voice message, the user can speak by bringing his or her
mouth close to the microphone 170C, and the voice signal is input into the microphone 170C.
The mobile phone may be provided with at least one microphone 170C.
In other embodiments, the mobile phone may be provided with two microphones 170C,
which can not only collect sound signals but also realize noise reduction function.
In other embodiments, the mobile phone may be provided with three, four or more
microphones 170C to collect sound signals, reduce noise, identify the sound source, realize
directional recording function, etc.
[0117]
The earphone jack 170D is used to connect a wired earphone.
The earphone interface 170D may be a USB interface 130, or a 3.5 mm open mobile terminal
platform (OMTP) standard interface or a cellular telecommunications industry association of
the USA (CTIA) standard interface.
[0118]
The sensor module 180 may include a pressure sensor, a gyro sensor, an air pressure
sensor, a magnetic sensor, an acceleration sensor, a distance sensor, a proximity light
sensor, a fingerprint sensor, a temperature sensor, a touch sensor, an ambient light sensor,
a bone conduction sensor, and the like.
[0119]
Of course, the mobile phone may also include a charging management module, a power
management module, a battery, buttons, indicators, and one or more SIM card interfaces,
etc., and the embodiments of the present application do not impose any restrictions on this.
[0120]
The software system of the above mobile phone can adopt a layered architecture, an event-
driven architecture, a micro-kernel architecture, a micro-service architecture, or a cloud
architecture.
The embodiment of the present application takes the Android system with a layered
architecture as an example to illustrate the software structure of a mobile phone.
[0121]
16-07-2025 - Page 27
Still taking a mobile phone as the above-mentioned electronic device as an example, FIG6
shows a software structure block diagram of the mobile phone according to an embodiment
of the present application.
[0122]
The layered architecture divides the software into several layers, each with clear roles and
division of labor.
The layers communicate with each other through software interfaces.
In some embodiments, the Android system is divided into four layers, namely, from top to
bottom, an application layer, an application framework layer, an Android runtime and
system library, and a kernel layer.
[0123]
The application layer can include a range of applications.
[0124]
As shown in FIG6 , the application layer may be installed with apps such as calls, memos,
browsers, contacts, cameras, galleries, calendars, maps, Bluetooth, music, videos, and short
messages.
[0125]
In the embodiment of the present application, as still shown in FIG. 6 , a projection
application may also be installed in the application layer.
Users can open the projection application from the desktop, settings function or drop-down
menu.
[0126]
The above-mentioned projection application can serve as a bridge between the mobile
phone (ie, the source device) and other electronic devices (ie, the target device) when
projecting content, and sends the projection content in the application to be projected in the
mobile phone to the target device.
For example, the projection application can receive screen projection events reported by the
application framework layer, and then the projection application can interact with the
running application (such as a video APP) and send the content being displayed or played in
the application as projection content to the target device via wireless communication
methods such as Wi-Fi.
16-07-2025 - Page 28
[0127]
In addition, the user can also use the above-mentioned projection application to set up a
binding relationship between the NFC tag and one or more electronic devices.
For example, you can set an option in the Cast app to bind an NFC tag.
After the phone detects that the user has turned on this option, the projection application
can display a list of electronic devices to be bound.
After the user selects one or more electronic devices to be bound in the list, the user can
place the mobile phone close to the NFC tag to be bound.
In this way, the mobile phone can write the identifier of the electronic device selected by the
user in the projection application into the NFC tag through the NFC signal, thereby
establishing a binding relationship between the NFC tag and one or more electronic devices
in the NFC tag.
[0128]
The application framework layer provides an application programming interface (API) and a
programming framework for applications in the application layer.
The application framework layer includes some predefined functions.
[0129]
In an embodiment of the present application, as shown in FIG6 , an NFC service may be run
in the application framework layer.
[0130]
Exemplarily, after the NFC function is enabled on the mobile phone, the NFC service can be
started in the application framework layer.
When the mobile phone approaches or touches the NFC tag, the NFC service can call the NFC
driver of the kernel layer to read the binding relationship stored in the NFC tag, thereby
obtaining the target device for this content projection.
Furthermore, the NFC service can report the projection event to the projection application,
thereby triggering the projection application to send the content currently displayed or
played by the mobile phone as the projection content to the target device, thereby starting
the content projection process.
[0131]
16-07-2025 - Page 29
Of course, as shown in Figure 6, the application framework layer can also include Wi-Fi
service, window manager, content provider, view system, phone manager, resource
manager, etc., and the embodiments of the present application do not impose any
restrictions on this.
[0132]
Among them, Wi-Fi services can be used to provide Wi-Fi related functions such as joining a
Wi-Fi network or establishing a Wi-Fi P2P connection with other electronic devices.
The above-mentioned window manager is used to manage window programs.
The window manager can obtain the display size, determine whether there is a status bar,
lock the screen, take screenshots, etc.
The above content providers are used to store and retrieve data and make the data
accessible to applications. The data may include video, images, audio, calls made and
received, browsing history and bookmarks, phonebooks, etc. The above-mentioned view
system includes visual controls, such as controls for displaying text, controls for displaying
pictures, etc. The view system can be used to build applications. The display interface can be
composed of one or more views. For example, a display interface including a text message
notification icon may include a view for displaying text and a view for displaying a picture.
The above-mentioned phone manager is used to provide the communication function of the
mobile phone. For example, the management of call status (including answering, hanging
up, etc.). The above resource managers provide various resources for applications, such as
localized strings, icons, images, layout files, video files, etc.
[0133]
As shown in FIG. 6 , the system library may include multiple functional modules.
For example: surface manager, media library, 3D graphics processing library (for example:
OpenGL ES), 2D graphics engine (for example: SGL), etc.
[0134]
The surface manager is used to manage the display subsystem and provide the fusion of 2D
and 3D layers for multiple applications.
The media library supports playback and recording of a variety of commonly used audio and
video formats, as well as static image files, etc. The media library can support multiple audio
and video encoding formats, such as: MPEG4, H.264, MP3, AAC, AMR, JPG, PNG, etc. The 3D
graphics processing library is used to implement 3D graphics drawing, image rendering,
compositing, and layer processing.
16-07-2025 - Page 30
2
A 2D graphics engine is a drawing engine for 2D drawings.
[0135]
Android Runtime includes core libraries and virtual machines.
Android runtime is responsible for scheduling and management of the Android system.
[0136]
The core library consists of two parts: one part is the function that needs to be called by the
Java language, and the other part is the Android core library.
[0137]
The application layer and the application framework layer run in virtual machines.
The virtual machine executes the Java files of the application layer and the application
framework layer as binary files.
The virtual machine is used to perform functions such as object life cycle management, stack
management, thread management, security and exception management, and garbage
collection.
[0138]
The kernel layer is the layer between hardware and software.
The kernel layer includes at least a display driver, a camera driver, an audio driver, a sensor
driver, etc., and the embodiments of the present application do not impose any restrictions
on this.
[0139]
A cross-device content projection method provided by an embodiment of the present
application will be described in detail below with reference to the accompanying drawings.
[0140]
Exemplarily, as shown in FIG. 7 , each NFC tag 701 may store its own NFC card number in the
NFC tag 701 when it leaves the factory.
16-07-2025 - Page 31
Furthermore, as shown in FIG. 7 , a flag bit may be pre-set in each NFC tag 701 , and the flag
bit may be used to indicate whether a binding relationship has been established between the
NFC tag 701 and the electronic device.
For example, when the flag bit in the NFC tag 701 is 00, it indicates that the NFC tag 701 has
not been bound to an electronic device; when the flag bit in the NFC tag 701 is 01, it indicates
that the NFC tag 701 has been bound to one or more electronic devices.
[0141]
When the user uses the NFC tag 701 for the first time, the user can use a preset projection
application to establish a binding relationship between the NFC tag 701 and one or more
electronic devices in the NFC tag 701 .
[0142]
Taking the mobile phone having the projection application installed as an example, as shown
in FIG8 , the method of using the projection application to establish the binding relationship
in the NFC tag 701 may include the following steps:
[0143]
S801. The mobile phone displays an NFC tag binding interface of the projection application,
which includes a list of devices to be bound.
[0144]
For example, when a user uses the NFC tag 701 for the first time, the user may turn on the
NFC function of the mobile phone and approach or touch the NFC tag 701 .
At this time, the mobile phone and the NFC tag 701 can interact through the NFC signal, so
that the mobile phone can read the NFC card number and the preset flag bit in the NFC tag
701.
If the flag bit is 00, it means that the NFC tag 701 has not been bound to the electronic
device.
Furthermore, as shown in FIG. 9 , the mobile phone may prompt the user to establish a
binding relationship between the NFC tag 701 and one or more electronic devices.
[0145]
If it is detected that the user clicks the confirmation button 901 shown in FIG. 9 , as shown in
FIG. 10 , the mobile phone may open the projection application and automatically jump to
the binding interface 1001 of the NFC tag 701 .
16-07-2025 - Page 32
In the binding interface 1001 , the mobile phone may display a device list 1002 consisting of
one or more electronic devices.
The electronic devices in the device list 1002 are all devices that can be bound to the NFC tag
. For example, the electronic devices in the device list 1002 may be one or more devices
logged in to the same account (eg, a Huawei account) as the mobile phone. For another
example, the electronic devices in the device list 1002 may be one or more devices
connected to the same Wi-Fi network as the mobile phone. The user can select the electronic
device that needs to be bound to the NFC tag 701 in the device list 1002 .
[0146]
In the embodiment of the present application, the NFC tag 701 can be bound to one or more
electronic devices.
That is, the user can select one or more electronic devices in the device list 1002 as binding
devices of the NFC tag 701 .
[0147]
Alternatively, as shown in FIG. 11 , a binding option 1101 for a single electronic device and a
binding option 1102 for multiple electronic devices may be pre-set in the projection
application.
If the user selects the binding option 1101 , the mobile phone may prompt the user to select
an electronic device from the device list to bind to the NFC tag 701 in the corresponding
binding interface. If the user selects the binding option 1102, as still shown in FIG. 11, the
mobile phone may display one or more pre-set device groups 1103 in the corresponding
binding interface, each device group including multiple electronic devices. For example,
smart TV and smart speaker 1 are one device group, smart speaker 1 and smart speaker 2
are one device group, and smart TV and smart light bulb are one device group. In this way,
the user can trigger the mobile phone to bind the NFC tag 701 with multiple electronic
devices in the device group by selecting a device group in the binding interface.
[0148]
S802. The mobile phone receives a first operation of the user selecting a binding device in
the device list.
[0149]
16-07-2025 - Page 33
In step S802 , after the mobile phone displays the binding interface of the projection
application, the user can select one or more electronic devices bound to the NFC tag 701
from the device list or device group listed in the binding interface.
The one or more electronic devices selected by the user may be referred to as binding
devices of the NFC tag 701 .
After the mobile phone detects that the user has selected a binding device on the binding
interface, the following steps S803-S804 may be continued.
[0150]
S803 . In response to the first operation, the mobile phone prompts the user to bring the
mobile phone close to the NFC tag 701 to be bound.
[0151]
Taking the binding devices as a smart TV and a smart light bulb as an example, after the
mobile phone detects that the user has selected the smart TV and the smart light bulb in the
above binding interface, the binding relationship between the NFC tag 701 and the smart TV
and the smart light bulb can be determined.
At this time, the mobile phone needs to write the binding relationship into the NFC tag 701.
Since the mobile phone and the NFC tag 701 need to communicate through a short-distance
NFC signal, as shown in FIG12 , if the mobile phone does not detect the NFC signal emitted
by the NFC tag 701, the mobile phone may display a prompt 1201 in the projection
application, and the prompt 1201 is used to guide the user to bring the mobile phone close
to or touch the NFC tag 701 waiting to be bound to the smart TV and the smart bulb.
[0152]
S804: The mobile phone writes the identification of the binding device into the NFC tag 701
to establish a binding relationship between the NFC tag 701 and the binding device.
[0153]
Exemplarily, the user may move the mobile phone close to or in contact with the NFC tag 701
according to the prompt shown in FIG. 12 .
When the distance between the mobile phone and the NFC tag 701 is close enough, the
mobile phone can detect the NFC signal sent by the NFC tag 701 .
Furthermore, as shown in FIG. 13 , the mobile phone may write the identifier of the binding
device set by the user in the binding interface into the NFC tag 701 . For example, the mobile
phone can write the MAC address, device name or IP address of the bound device into the
16-07-2025 - Page 34
NFC tag 701. In this way, a binding relationship between the NFC tag 701 and the binding
device is established in the NFC tag 701. Subsequently, a source device such as a mobile
phone that performs content projection can determine one or more electronic devices
bound to the NFC tag 701, that is, the target device for content projection, by reading the
identifier of the bound device in the NFC tag 701.
[0154]
In addition, after the mobile phone writes the identification of the above-mentioned bound
device into the NFC tag 701, the NFC tag 701 can modify the preset flag bit from 00 to 01 to
indicate that the current NFC tag 701 has been bound to one or more electronic devices.
[0155]
In some embodiments, after the mobile phone writes the identifier of the bound device into
the NFC tag 701, the user can continue to set the projection strategy of the bound device
bound to the NFC tag 701 when performing content projection in the projection application.
[0156]
Taking the binding device of NFC tag 701 as a smart TV as an example, after the mobile
phone writes the logo of the smart TV into NFC tag 701, the user can be prompted to set the
projection strategy when projecting content to the smart TV in the projection application.
As shown in FIG. 14 , the mobile phone may provide different projection instructions
corresponding to different NFC operations in the setting interface 1301 for the user to select.
For example, the user may set that when the NFC tag 701 is touched once, the
corresponding projection instruction is to start projection.
For example, the user may set that when the NFC tag 701 is touched twice in succession, the
corresponding projection instruction is to play the next episode (or the next song). For
another example, the user may set that when the NFC tag 701 is touched for more than a
preset time, the corresponding projection instruction is to exit the current content
projection.
[0157]
Then, after receiving the projection strategy set by the user in the setting interface 1301, the
mobile phone can establish an association relationship between the NFC tag 701, the smart
TV and the above projection strategy.
16-07-2025 - Page 35
Subsequently, the mobile phone can be triggered to project content to the smart TV
according to the projection strategy set by the user by approaching or touching the NFC tag
701, thereby simplifying the operation process when projecting content across devices.
[0158]
Taking the example of a smart TV, a smart speaker and a smart light bulb as the bound
devices of NFC tag 701, after the mobile phone writes the identifiers of the smart TV, the
smart speaker and the smart light bulb into NFC tag 701, the user can also be prompted in
the projection application to set a projection strategy for projecting content to these three
bound devices.
For example, as shown in FIG. 15 , the user can set in the setting interface 1401 that when
projecting content to a smart TV, smart speaker, and smart light bulb, the display content of
the source device can be projected to the smart TV for display, and the audio content of the
source device can be projected to the smart speaker for playback, and the smart light bulb
can change the lighting effect according to the display content or audio content. Of course,
the user can further set a specific projection strategy when projecting display content in the
smart TV, a specific projection strategy when projecting audio content in the speaker, etc.,
and the embodiment of the present application does not impose any restrictions on this.
[0159]
Similarly, after the mobile phone receives the projection strategy set by the user in the
setting interface 1401, it can establish an association relationship between the NFC tag 701,
the bound device (i.e., the smart TV, smart speaker and smart bulb) and the above projection
strategy.
Subsequently, the mobile phone can be triggered to project content to the above three
bound devices according to the projection strategy set by the user by approaching or
touching the NFC tag 701, thereby simplifying the operation process when projecting
content across devices.
[0160]
It should be noted that the projection strategy of the device bound to the NFC tag 701 when
projecting content can be manually set by the user using the projection application, or can
be pre-set by the mobile phone according to information such as the type, location, and
device capabilities of the bound device.
16-07-2025 - Page 36
For example, when the bound devices of NFC tag 701 are smart speaker 1 and smart speaker
2, the default projection strategy of the mobile phone can be to use the smart speaker
closest to the user to project content.
[0161]
In other embodiments, the above projection strategy may also be dynamically set by the
source device during the process of projecting content to the device bound to the NFC tag
701 .
For example, when a mobile phone projects content to a device bound to the NFC tag 701
(such as a smart TV and a smart speaker), the audio playback capabilities of the smart TV and
the smart speaker can be dynamically acquired. Furthermore, the mobile phone can
determine to project the audio content on the smart TV and/or smart speaker based on the
audio playback capabilities of the smart TV and smart speaker. The embodiments of the
present application do not impose any restrictions on the specific content of the projection
strategy and the specific setting method of the projection strategy.
[0162]
Exemplarily, the user can set one or more corresponding binding devices for different NFC
tags according to the above method.
When the user needs to project content on one or a group of bound devices, the user can
turn on the NFC function of the source device and bring it close to or touch the
corresponding NFC tag, so as to start the content projection process by using one or more
bound devices bound to the NFC tag as the target devices for this content projection.
[0163]
The following will take a mobile phone as an example of a source device to illustrate a
method for projecting content to a target device by touching an NFC tag 701 with the mobile
phone. As shown in FIG. 16 , the method may include the following steps:
[0164]
S1501 . In response to a tapping operation between a mobile phone and an NFC tag 701 , the
mobile phone obtains one or more bound devices bound to the NFC tag 701 .
[0165]
Exemplarily, through the above steps S801 - S804 , the mobile phone has set a
corresponding binding device for the NFC tag 701 .
16-07-2025 - Page 37
Then, when the user wants to project the content (such as display content, audio content) in
the mobile phone (i.e., the source device) to the bound device of the NFC tag 701, as shown
in Figure 17, the user can turn on the NFC function of the mobile phone and touch (or
approach) the NFC tag 701, that is, perform a touch operation between the mobile phone
and the NFC tag 701.
[0166]
In response to the touch operation between the mobile phone and the NFC tag 701, the
mobile phone can read the identifiers of one or more bound devices bound to the NFC tag
701 from the NFC tag 701, and the bound devices can participate in the content projection as
the target devices of the mobile phone.
In other words, the user can use the source device to touch the NFC tag through a tap
operation, which can trigger the source device to obtain the target device participating in
this content projection, thereby automatically completing the subsequent content projection
process with the target device, simplifying the operation process during content projection
and improving the efficiency of multi-device collaboration.
[0167]
Of course, if the NFC tag 701 does not store the identifier of the bound device, the mobile
phone can establish a corresponding relationship between the NFC tag 701 and the
corresponding bound device by executing the above steps S801-S804.
[0168]
S1502: When the bound device of the NFC tag 701 is an electronic device, the mobile phone
sends the projection content to the bound device to start the current content projection.
[0169]
When the mobile phone reads the identification of only one bound device in the NFC tag 701,
it means that there is only one bound device bound to the NFC tag 701, and the target device
for content projection this time is the bound device.
[0170]
Taking the bound device as a smart TV as an example, after the mobile phone reads the logo
of the smart TV in the NFC tag 701, as shown in Figure 18, the mobile phone can use the
smart TV as the target device for this content projection and send the projection content to
the smart TV to start content projection.
16-07-2025 - Page 38
The projected content may include the content being played by the mobile phone, for
example, the audio content and/or display content being played by the mobile phone.
The displayed content may include pictures, scenes in a video, or part or all of the content in
the current display interface.
[0171]
For example, the mobile phone can query whether the currently connected Wi-Fi network
includes the smart TV according to the identification of the smart TV.
If a smart TV is included, it means that the smart TV has been connected to the Wi-Fi
network. Then, the mobile phone can dynamically send the projection content to the smart
TV through the Wi-Fi network.
If the smart TV is not included, it means that the smart TV has not yet been connected to the
Wi-Fi network where the mobile phone is located. The mobile phone can prompt the user to
connect the smart TV to the same Wi-Fi network where the mobile phone is located.
Furthermore, the mobile phone can dynamically send the projection content to the smart TV
through the Wi-Fi network.
[0172]
Alternatively, if the Wi-Fi network where the mobile phone is located does not include the
smart TV, the mobile phone can also automatically establish a wireless communication
connection with the smart TV according to the read identification of the smart TV (such as
the MAC address of the smart TV).
For example, a mobile phone may establish a Bluetooth connection or a Wi-Fi P2P
connection with a smart TV, and the embodiments of the present application do not impose
any restrictions on this.
[0173]
In addition, the projection content sent by the mobile phone to the smart TV may include the
display content of the mobile phone.
For example, a mobile phone can send each frame of the real-time displayed image to a
smart TV through mirroring, and the smart TV will synchronously display the display
interface of the mobile phone.
For another example, a mobile phone can send partial display content such as videos and
pictures in the mobile phone display interface to a smart TV for display through DLNA (digital
living network alliance) screen projection.
[0174]
16-07-2025 - Page 39
Exemplarily, when a mobile phone contacts or approaches the above-mentioned NFC tag
701, if the mobile phone is displaying the playback interface of video A, then when the bound
device of the NFC tag 701 is a smart TV, the mobile phone can act as a source device to send
the entire playback interface (i.e., all displayed content in the display interface) as projection
content to the smart TV, or the mobile phone can act as a source device to send the video
image of video A in the playback interface (i.e., part of the displayed content in the display
interface) as projection content to the smart TV.
[0175]
For another example, when a mobile phone touches or approaches the NFC tag 701, if the
mobile phone is displaying a playlist of a video APP, then when the bound device of the NFC
tag 701 is a smart TV, the mobile phone can also act as a source device to send the displayed
playlist to the smart TV as projection content.
Subsequently, if the mobile phone detects that the user selects to play video A in the above
play list, the mobile phone can continue to send the play interface of video A or the video
image of video A as the projection content to the smart TV.
[0176]
Of course, the projection content sent by the mobile phone to the smart TV may also include
the audio content being played by the mobile phone. For example, the audio content may be
an audio file corresponding to the video picture being displayed by the mobile phone.
After receiving the projection content sent by the mobile phone in real time, the smart TV
can display or play the projection content to complete the content projection.
[0177]
In some embodiments, still taking the target device for content projection as a smart TV,
when a mobile phone is projecting content to the smart TV, the user can trigger the mobile
phone to send a corresponding projection instruction to the smart TV through interaction
between the mobile phone and the NFC tag 701, thereby realizing the corresponding control
function during the content projection process.
[0178]
Exemplarily, when the user sets a binding device for the NFC tag 701 in the projection
application, the projection strategy associated with the NFC tag 701 and the binding device
may be pre-set.
16-07-2025 - Page 40
For example, the projection strategy includes different projection instructions corresponding
to different NFC operations.
Exemplarily, the projection instruction corresponding to the NFC operation of the mobile
phone touching the NFC tag 701 twice continuously can be set to play the next episode (or
the next song).
[0179]
Then, during the process of projecting content from the mobile phone to the smart TV, if the
mobile phone detects that the user inputs an operation of touching the NFC tag 701 twice in
succession, the mobile phone can send a projection instruction to play the next episode (or
next song) to the smart TV.
The smart TV can respond to the projection instruction to play the next episode (or the next
song).
That is to say, during the content projection process, the user can use the source device to
input different NFC operations to the NFC tag to implement corresponding control functions,
thereby enriching the user experience in the content projection scenario.
[0180]
S1503: When the NFC tag 701 is bound to multiple electronic devices, the mobile phone
determines the main device for current content projection.
[0181]
The master device (master) for this content projection may be a source device (ie, a mobile
phone), or may be one of a plurality of bound devices bound to the NFC tag 701 .
The master device can be used as a control node to connect and interact with other devices (i.
e., slave devices) through a star topology.
[0182]
In some embodiments, when there are multiple bound devices to the NFC tag 701, the
mobile phone can determine the specific master device according to information such as
device types and device capabilities of the multiple bound devices.
For example, the mobile phone can query the computing capabilities of the multiple bound
devices and determine the bound device with the strongest computing capability as the
main device for this content projection. At this time, the mobile phone and other bound
devices can serve as slave devices of the main device.
16-07-2025 - Page 41
[0183]
In other embodiments, the mobile phone may be pre-set with specific master devices
corresponding to different content projection scenarios.
For example, when the bound devices are a smart TV and a smart light bulb, the master
device can be set to be the smart TV, and the slave devices to be the mobile phone and the
smart light bulb.
For another example, when the bound devices are smart speaker 1 and smart speaker 2, the
master device can be set to be a mobile phone, and the slave devices to be smart speaker 1
and smart speaker 2.
For another example, when the bound devices are a smart TV and a smart speaker, the
master device can be set to be a mobile phone, and the slave devices can be set to be the
smart TV and the smart speaker. Then, the mobile phone can determine the specific master
device corresponding to the content projection scene composed of the multiple bound
devices according to the identifiers of the multiple bound devices read from the NFC tag 701.
[0184]
S1504: If the mobile phone is the main device, the mobile phone sends the projection
content to each bound device according to the projection strategy.
[0185]
If the mobile phone determines that the main device for this content projection is the mobile
phone (i.e., the source device), the mobile phone can serve as the control node for this
content projection, and send the projection content to each bound device (i.e., the target
device) in real time according to a certain projection strategy, so that each bound device
starts to play or display the projection content after receiving it.
Among them, the above-mentioned projection strategy can be pre-set by the user when
binding the NFC tag 701, or it can be pre-set by the mobile phone according to the device
type, device capabilities and other information of the bound device, or it can be dynamically
generated after the mobile phone determines that it is the main device. The embodiment of
the present application does not impose any restrictions on this.
[0186]
Exemplarily, as shown in Figure 19, when the bound devices of NFC tag 701 are smart
speaker 1 and smart speaker 2, the mobile phone can act as the master device when
projecting content to smart speaker 1 and smart speaker 2, and smart speaker 1 and smart
speaker 2 can act as slave devices of the mobile phone.
16-07-2025 - Page 42
In this projection scenario, the projection strategy can be set to be related to the distance
between the mobile phone and smart speaker 1 and smart speaker 2.
[0187]
For example, the mobile phone can detect the distance between the mobile phone and
smart speaker 1 and smart speaker 2 respectively.
When the distance between the mobile phone and the smart speaker 1 is less than the
preset value, and the distance between the mobile phone and the smart speaker 2 is greater
than the preset value, it means that the user is closer to the smart speaker 1 and farther
away from the smart speaker 2.
Then, the mobile phone can act as a master device to send the projection content to the
smart speaker 1, and the smart speaker 1 plays the projection content to complete the
content projection. Of course, the mobile phone can also send the projected content to the
smart speaker closest to the mobile phone by default.
[0188]
Alternatively, if the distances between the mobile phone and smart speaker 1 and smart
speaker 2 are both less than the preset values, it means that the distances between the user
and smart speaker 1 and smart speaker 2 are both relatively close.
Then, the mobile phone can send the projection content to smart speaker 1 and smart
speaker 2 respectively according to the projection strategy of stereo playback. For example,
the mobile phone can send the low-frequency components in the projected content to smart
speaker 1, and smart speaker 1 plays the low-frequency components in the projected
content. At the same time, the mobile phone can send the high-frequency components in the
projected content to smart speaker 2, and smart speaker 2 plays the high-frequency
components in the projected content. For another example, the mobile phone can send the
audio file corresponding to the left channel in the projected content to smart speaker 1, and
at the same time send the audio file corresponding to the right channel in the projected
content to smart speaker 2, so that smart speaker 1 and smart speaker 2 play the audio files
of the left channel and right channel in the projected content respectively. Of course, if the
above-mentioned bound devices also include more smart speakers in addition to smart
speaker 1 and smart speaker 2, the mobile phone can send the corresponding audio
components in the projected content to each smart speaker according to the above method,
so that multiple speakers can play the received audio components respectively to achieve
stereo or surround sound playback effects.
[0189]
16-07-2025 - Page 43
For example, before the mobile phone sends the projection content to smart speaker 1 and
smart speaker 2, it can also send a synchronization instruction to smart speaker 1 and smart
speaker 2. Smart speaker 1 and smart speaker 2 can synchronize the time with the mobile
phone according to the synchronization instruction to ensure that the playback progress of
smart speaker 1 and smart speaker 2 is the same.
For example, the mobile phone may mark one or more timestamps in the projection content
to be sent, and send the projection content and the timestamps in the projection content to
smart speakers 1 and 2. Since the time of smart speaker 1, smart speaker 2 and mobile
phone is synchronized after the time synchronization, smart speaker 1 and smart speaker 2
can play each projected content according to the timestamp in the projected content,
ensuring that the playback progress of smart speaker 1 and smart speaker 2 is the same.
[0190]
In addition, the mobile phone can also calculate the transmission delay when smart speaker
1 and smart speaker 2 respond to the above synchronization instructions.
For example, the transmission delay when smart speaker 1 responds to the above
synchronization command is 300ms, and the transmission delay when smart speaker 2
responds to the above synchronization command is 500ms. Then, the mobile phone can
calculate the distance between the mobile phone and smart speaker 1 and smart speaker 2
respectively according to the transmission delay. Of course, the mobile phone can also
detect the distance between the mobile phone and the smart speakers 1 and 2 through
distance sensors, infrared sensors, etc., and the embodiments of the present application do
not impose any restrictions on this.
[0191]
In some embodiments, in order to ensure that smart speaker 1 and smart speaker 2 can
synchronously play the projection content sent by the mobile phone, the mobile phone can
also send the projection content to smart speaker 1 and smart speaker 2 respectively
according to the transmission delay of smart speaker 1 and smart speaker 2.
Still taking the example that the transmission delay of smart speaker 1 is 300ms and the
transmission delay of smart speaker 2 is 500ms, the mobile phone can send the same
projection content to smart speaker 2 200ms in advance before sending the projection
content to smart speaker 1. In this way, smart speaker 1 and smart speaker 2 can receive the
projection content sent by the mobile phone at the same time and start content projection.
[0192]
16-07-2025 - Page 44
Alternatively, as still shown in Figure 19, when the mobile phone is the main device for this
content projection, and smart speaker 1 and smart speaker 2 are slave devices of the mobile
phone, the mobile phone can display the setting interface of the projection strategy.
In this setting interface, users can manually set which smart speaker will be used to play the
projected content sent from the mobile phone during this content projection. In addition,
the mobile phone can save the projection strategies set by the user for the mobile phone,
smart speaker 1 and smart speaker 2. Later, when the mobile phone again acts as the main
device to project content to smart speaker 1 and smart speaker 2, the mobile phone can
project content according to the above-mentioned stored projection strategies. That is to
say, the user can manually set corresponding projection strategies for multiple devices
participating in content projection during the content projection process.
[0193]
Exemplarily, as shown in FIG20 , when the bound devices of the NFC tag 701 are smart TVs
and smart speakers, the mobile phone can act as a master device when projecting content to
the smart TVs and smart speakers, and the smart TVs and smart speakers can act as slave
devices of the mobile phone.
In this projection scenario, the projection strategy can be set to use the smart TV to play the
display content in the projection content, and use the smart speaker to play the audio
content in the projection content.
[0194]
Then, the mobile phone can serve as a master device to send the display content in this
projection to the smart TV, and the smart TV starts to display the display content.
At the same time, the mobile phone can send the audio content in this projection to the
smart speaker, and the smart speaker starts playing the audio content.
[0195]
Alternatively, the mobile phone can serve as a master device to send the display content and
audio content in the current projection content to the smart TV, and the smart TV plays the
display content and audio content.
At the same time, the mobile phone can send the audio content in this projection to the
smart speaker, and the smart speaker starts playing the audio content. That is, the smart TV
and smart speaker can play the projected audio content at the same time. Among them, the
16-07-2025 - Page 45
above-mentioned smart TVs may include one or more, and the above-mentioned smart
speakers may also include one or more, and the embodiments of the present application do
not impose any restrictions on this.
[0196]
Similarly, in order to ensure that the display content displayed by the smart TV is
synchronized with the audio content played by the smart speaker, the mobile phone can
perform time synchronization with the smart TV and the smart speaker before sending the
above display content and audio content to the smart TV and the smart speaker.
Furthermore, the mobile phone can send the display content and audio content with
timestamps to the smart TV and smart speaker respectively, so that the smart TV and smart
speaker can synchronously project the content according to the timestamps.
[0197]
Alternatively, the projection strategy when the mobile phone projects content to the smart
TV and smart speaker can be set dynamically.
For example, a mobile phone can act as a master device to obtain the device capabilities of
smart TVs and smart speakers. Taking the example of a smart TV having display and audio
playback capabilities and a smart speaker having audio playback capabilities, the mobile
phone can dynamically determine to project the display content in this projection to the
smart TV for display, and project the audio content in this projection to the smart TV and the
smart speaker for playback at the same time. Furthermore, the mobile phone can act as a
master device to send the display content and audio content in the current projection
content to the smart TV, and at the same time send the audio content in the current
projection content to the smart speaker.
[0198]
S1505: If the mobile phone is not the master device, the mobile phone sends the projection
content to the master device, and the master device controls other bound devices to start
the content projection according to the projection strategy.
[0199]
If the mobile phone determines that the main device for this content projection is one of the
multiple bound devices of the NFC tag 701, the mobile phone can send the current
projection content to the main device, and the main device controls other bound devices to
start content projection according to a certain projection strategy.
16-07-2025 - Page 46
[0200]
Exemplarily, as shown in FIG. 21 , when the bound devices of the NFC tag 701 are a smart TV
and a smart light bulb, the smart TV can be used as a master device for content projection,
and the smart light bulb can be used as a slave device of the smart TV.
In this projection scenario, the projection strategy can be set to use the smart TV to display
and play the projection content, and the smart TV can control the lighting effect of the smart
bulb.
[0201]
Then, the mobile phone (ie, the source device) can send the projection content that needs to
be projected this time to the smart TV (ie, the main device).
Of course, the mobile phone can also send the projection strategy of this content projection
to the smart TV.
Alternatively, the smart TV may pre-store the projection strategy when the slave device is a
smart light bulb, and the embodiment of the present application does not impose any
restrictions on this.
Furthermore, the smart TV can act as a master device to start displaying and playing the
projection content sent from the mobile phone. At the same time, the smart TV can send
corresponding control instructions to the smart light bulb according to the projected
content, so that the smart light bulb can project different lighting effects during the content
projection process.
[0202]
For example, when a smart TV starts to display and play projected content, the smart TV can
send a light-off command to a smart light bulb to control the smart light bulb to turn off the
light source.
For another example, a smart TV can obtain the type of video being played. If a horror video
is being played, the smart TV can control the smart light bulb to display a blue light source; if
a love video is being played, the smart TV can control the smart light bulb to display a pink
light source, etc., so that the user can get a better scene experience during the content
projection process.
[0203]
In other embodiments, when the mobile phone obtains that there are multiple bound
devices bound to the NFC tag 701 by reading the NFC tag 701, the mobile phone may also
16-07-2025 - Page 47
default to itself as the main device in this content projection process. At this time, the mobile
phone does not need to execute the above steps S1503 and S1505, and can send the
projection content to each bound device according to the projection strategy according to
the relevant method in step S1504 to complete this content projection.
[0204]
It can be seen that in the content projection method provided in the embodiment of the
present application, the user can conveniently and quickly project the projection content in
the source device to the target device required by the user by touching the NFC tag, thereby
realizing the "touch and cast" function.
In addition, the source device can project the projection content to multiple target devices at
the same time, and achieve different projection effects in different projection scenarios
through the coordinated cooperation of multiple target devices, thereby improving the user
experience and the collaborative work efficiency between multiple devices.
[0205]
In some embodiments, after the user sets the binding device of the NFC tag 701 in the
projection application of the mobile phone, the mobile phone can also back up the binding
relationship between the NFC tag 701 and the binding device to the application server of the
projection application.
For example, the mobile phone can send the NFC card number of the NFC tag 701 and the
identifiers of one or more binding devices bound to the NFC tag 701 to the application
server, so that the application server establishes a binding relationship between the NFC tag
701 and the corresponding binding device.
[0206]
In this way, when the user changes the mobile phone (ie, the source device), the user can
install and log in to the projection application on the new source device, and then the new
source device can re-acquire the binding relationship between the NFC tag 701 and the
corresponding binding device from the application server of the projection application.
Then, when the user touches the NFC tag 701 with a new source device, the new source
device can also execute the above steps S1501-S1505 to project the content to the
corresponding bound device.
[0207]
16-07-2025 - Page 48
In some embodiments, after the user sets the binding device and projection strategy of the
NFC tag 701 in the projection application of the mobile phone, the user can also share the
NFC tag 701, the corresponding binding device and the corresponding projection strategy
with other users.
For example, user A can share the NFC tag 701, the bound device, and the projection
strategy with user A's family (eg, user A's parents) via WeChat or other means.
Then, after receiving the shared content, the mobile phone of the parent of user A can save
the corresponding relationship between the NFC tag 701, the bound device and the
projection strategy. Subsequently, when the parent of user A touches the NFC tag 701 with
his/her mobile phone, the mobile phone can also execute the above steps S1501-S1505 to
project the content to the corresponding bound device.
[0208]
In addition, when the user sets a projection strategy for the device bound to the NFC tag
701, the user may also set specific projection content, projection time, etc. in the projection
strategy.
For example, the user can set the projection content corresponding to the NFC tag 701 for
his or her child to be learning video A, and the projection time is 1 hour. Then, when the user
touches the NFC tag 701 with his mobile phone, or when the user shares the projection
strategy with his parents and the parents touch the NFC tag 701 with their mobile phone, the
mobile phone can project the content to the corresponding bound device according to the
projection content and projection time set by the user in the projection strategy, so that the
mobile phone can complete the content projection in a targeted manner, reducing the
difficulty of operation for the elderly and children when performing content projection.
[0209]
An embodiment of the present application discloses an electronic device, including a
processor, and a memory, a communication interface, an input device, and an output device
connected to the processor.
The input device and the output device may be integrated into one device. For example, a
touch sensor may be used as an input device, a display screen may be used as an output
device, and the touch sensor and the display screen may be integrated into a touch screen.
[0210]
At this time, as shown in Figure 22, the above-mentioned electronic device may include: a
touch screen 2201, the touch screen 2201 includes a touch sensor 2206 and a display screen
16-07-2025 - Page 49
2207; one or more processors 2202; a memory 2203; one or more applications (not shown); a
communication interface 2208; and one or more computer programs 2204, and the above-
mentioned devices can be connected via one or more communication buses 2205.
The one or more computer programs 2204 are stored in the memory 2203 and configured to
be executed by the one or more processors 2202 . The one or more computer programs
include instructions, and the instructions can be used to execute the various steps in
the above embodiments. Among them, all relevant contents of each step involved in the
above method embodiment can be referred to the functional description of the
corresponding physical device, and will not be repeated here.
[0211]
Exemplarily, the processor 2202 may be specifically the processor 110 shown in FIG. 5 , the
memory 2203 may be specifically the internal memory 121 shown in FIG. 5 , the display
screen 2207 may be specifically the display screen 194 shown in FIG. 5 , and the touch sensor
may be specifically the touch sensor in the sensor module 180 shown in FIG. 5 , and the
embodiments of the present application do not impose any restrictions on this.
[0212]
Through the description of the above implementation methods, technical personnel in the
relevant field can clearly understand that for the convenience and simplicity of description,
only the division of the above-mentioned functional modules is used as an example. In actual
applications, the above-mentioned functions can be assigned to different functional modules
as needed, that is, the internal structure of the device can be divided into different functional
modules to complete all or part of the functions described above.
The specific working processes of the systems, devices and units described above can refer
to the corresponding processes in the aforementioned method embodiments, which will not
be repeated here.
[0213]
The functional units in the various embodiments of the present application may be
integrated into one processing unit, or each unit may exist physically separately, or two or
more units may be integrated into one unit.
The above integrated unit can be implemented in the form of hardware or in the form of
software functional unit.
[0214]
16-07-2025 - Page 50
If the integrated unit is implemented in the form of a software functional unit and sold or
used as an independent product, it can be stored in a computer-readable storage medium.
Based on this understanding, the technical solution of the embodiments of the present
application can essentially be embodied in the form of a software product, or in other words,
the part that contributes to the prior art or all or part of the technical solution. The computer
software product is stored in a storage medium and includes a number of instructions for
enabling a computer device (which can be a personal computer, a server, or a network
device, etc.) or a processor to execute all or part of the steps of the methods described in the
embodiments of the present application.
The aforementioned storage media include: flash memory, mobile hard disk, read-only
memory, random access memory, magnetic disk or optical disk and other media that can
store program codes.
[0215]
The above is only a specific implementation of the embodiment of the present application,
but the protection scope of the embodiment of the present application is not limited to this.
Any changes or substitutions within the technical scope disclosed in the embodiment of the
present application should be covered within the protection scope of the embodiment of the
present application.
Therefore, the protection scope of the embodiments of the present application shall be
based on the protection scope of the claims.
16-07-2025 - Page 1
Patent Translate
Powered by EPO and Google
Notice
This translation is machine-generated. It cannot be guaranteed that it is intelligible, accurate,
complete, reliable or fit for specific purposes. Critical decisions, such as commercially
relevant or financial decisions, should not be based on machine-translation output.
CLAIMS CN110958475A
1.
A cross-device content projection method, characterized by comprising:
The first electronic device starts playing the first content;
The first electronic device obtains N second electronic devices bound to the NFC tag from the
NFC tag, where N is an integer greater than 1;
The first electronic device projects the first content to at least one second electronic device
among the N second electronic devices according to a preset projection strategy for
continuous playback.
2.
The method according to claim 1 is characterized in that the first electronic device obtains N
second electronic devices bound to the NFC tag from the NFC tag, comprising:
In response to a bump operation in which the first electronic device approaches or contacts
the NFC tag, the first electronic device reads the identifiers of the N second electronic
devices stored in the NFC tag to determine the N second electronic devices bound to the NFC
tag; or,
After the first electronic device detects the NFC signal from the NFC tag using the NFC chip, it
reads the identifiers of the N second electronic devices stored in the NFC tag to determine
the N second electronic devices bound to the NFC tag; wherein the NFC chip is included in
the first electronic device.
3.
16-07-2025 - Page 2
The method according to claim 1 or 2, characterized in that the first electronic device
projects the first content to at least one of the N second electronic devices for continuous
playback according to a preset projection strategy, comprising:
The first electronic device sends the first content to at least one second electronic device
among the N second electronic devices for playback according to a preset projection
strategy.
4.
The method according to claim 3, characterized in that the N second electronic devices
include a first speaker and a second speaker;
The first electronic device sends the first content to at least one of the N second electronic
devices for playback according to a preset projection strategy, including:
The first electronic device sends the first content to the first speaker for playing, and the first
speaker is the speaker closest to the first electronic device; or
The first electronic device sends the first content to the first speaker and the second speaker
for playing.
5.
The method according to claim 4, wherein the first electronic device sends the first content
to the first speaker and the second speaker for playing, comprising:
The first electronic device sends the first audio component in the first content to the first
speaker for playing; and the first electronic device sends the second audio component in the
first content to the second speaker for playing.
6.
The method according to claim 3, characterized in that the N second electronic devices
include speakers and televisions;
The first electronic device sends the first content to at least one of the N second electronic
devices for playback according to a preset projection strategy, including:
The first electronic device sends the display content in the first content to the television for
playing; and the first electronic device sends the audio content in the first content to the
speaker for playing; or
The first electronic device sends the display content in the first content to the television for
playing; and the first electronic device sends the audio content in the first content to the
television and the speaker for playing.
7.
16-07-2025 - Page 3
The method according to claim 1 or 2, characterized in that after the first electronic device
obtains N second electronic devices bound to the NFC tag from the NFC tag, it also includes:
The first electronic device determines a master device among the N second electronic
devices;
The first electronic device projects the first content to at least one of the N second electronic
devices for continuous playback according to a preset projection strategy, including:
The first electronic device sends the first content to the master device, so that the master
device controls at least one second electronic device among the N second electronic devices
to play the first content according to a preset projection strategy.
8.
The method according to claim 7, characterized in that the N second electronic devices
include a television and a lamp;
The first electronic device determines a master device among the N second electronic
devices, including:
The first electronic device determines the television as a master device among the N second
electronic devices;
The preset projection strategy includes: the television plays the display content and audio
content in the first content, and the television sends a control instruction to the lamp
according to the first content to control the brightness or color of the lamp.
9.
The method according to claim 7 or 8, characterized in that after the first electronic device
determines the master device among the N second electronic devices, it further comprises:
The first electronic device sends the stored projection strategy to the main device.
10.
The method according to any one of claims 3 to 9, characterized in that before the first
electronic device projects the first content to at least one of the N second electronic devices
for continued playback according to a preset projection strategy, it further comprises:
The first electronic device performs time synchronization with the N second electronic
devices;
The first content sent by the first electronic device carries a timestamp, and the timestamp is
used to indicate the playback progress of the first content.
11.
16-07-2025 - Page 4
The method according to any one of claims 1 to 10, characterized in that after the first
electronic device obtains N second electronic devices bound to the NFC tag from the NFC
tag, it also includes:
The first electronic device receives a projection strategy input by a user to the N second
electronic devices.
12.
A cross-device content projection method, characterized by comprising:
The first electronic device displays a binding interface of a near field communication NFC tag,
wherein the binding interface includes a list of candidate devices waiting to be bound to the
NFC tag, and the candidate devices in the candidate device list are located in the same
communication network as the first electronic device;
The first electronic device detects a first operation of a user selecting M second electronic
devices in the candidate device list, where M is an integer greater than 0;
In response to the first operation, the first electronic device prompts the user to bring the
first electronic device close to or in contact with the NFC tag;
The first electronic device writes the identifiers of the M second electronic devices into the
NFC tag to establish a binding relationship between the NFC tag and the M second electronic
devices.
13.
The method according to claim 12, wherein the first electronic device displays a binding
interface of the NFC tag, comprising:
The first electronic device reads a preset flag bit in the NFC tag;
If the value in the flag bit is a first preset value, the first electronic device opens a preset
projection application to display a binding interface of the NFC tag.
14.
The method according to claim 13, characterized in that after the first electronic device
writes the identifiers of the M second electronic devices into the NFC tag, it also includes:
The first electronic device modifies the value of the flag bit from the first preset value to a
second preset value.
15.
16-07-2025 - Page 5
The method according to any one of claims 12 to 14, characterized in that after the first
electronic device writes the identifiers of the M second electronic devices into the NFC tag, it
further comprises:
The first electronic device displays a setting interface for the projection strategy;
The first electronic device receives projection strategies input by a user for the M second
electronic devices in the setting interface, and saves the projection strategies.
16.
The method according to claim 15, characterized in that, when M=1, the projection strategy
includes a correspondence between different NFC operations and projection instructions.
17.
The method according to claim 15, characterized in that, when M>1, the projection strategy
includes content projection rules set for each second electronic device.
18.
The method according to claim 17, characterized in that
When the M second electronic devices include a first speaker and a second speaker, the
projection strategy is: using the speaker closest to the source device to play the projection
content, or the projection strategy is: using the first speaker to play the first audio
component in the projection content and using the second speaker to play the second audio
component in the projection content;
When the M second electronic devices include a television and a sound box, the projection
strategy is: using the television to play the display content in the projection content, and
using the sound box to play the audio content in the projection content; or using the
television to play the display content in the projection content, and using the sound box and
the television to play the audio content in the projection content;
When the M second electronic devices include a television and a lamp, the projection
strategy is: using the television to play the projection content, and controlling the lighting
effect of the lamp by the television.
19.
The method according to any one of claims 12 to 18, characterized in that after the first
electronic device writes the identifiers of the M second electronic devices into the NFC tag, it
further comprises:
16-07-2025 - Page 6
The first electronic device sends the binding relationship between the NFC tag and the M
second electronic devices to other electronic devices or a server.
20.
The method according to any one of claims 12 to 19, characterized in that
The candidate devices in the candidate device list and the first electronic device are located
in the same Wi-Fi network, or the candidate devices in the candidate device list and the first
electronic device are bound to the same account; or,
The first electronic device writes the identification of the second electronic device into the
NFC tag, comprising: in response to a bump operation of the first electronic device
approaching or contacting the NFC tag, the first electronic device writes the identification of
the second electronic device into the NFC tag; or, the first electronic device detects an NFC
signal from the NFC tag using an NFC chip, and then writes the identification of the second
electronic device into the NFC tag, the NFC chip being included in the first electronic device;
or,
The first electronic device reads a preset flag bit in the NFC tag, including: in response to a
tap operation in which the first electronic device approaches or contacts the NFC tag, the
first electronic device reads a preset flag bit in the NFC tag; or, the first electronic device
reads a preset flag bit in the NFC tag after detecting an NFC signal from the NFC tag using an
NFC chip.
21.
A content projection system, characterized in that it includes a first electronic device, N
second electronic devices and an NFC tag, N is an integer greater than 1; the NFC tag stores
a binding relationship between the NFC tag and the N second electronic devices; wherein the
first electronic device is used to execute the cross-device content projection method as
described in any one of claims 1-11 or claims 12-20.
22.
The system according to claim 21, wherein the N second electronic devices include a master
device;
The master device is used to: receive the first content sent by the first electronic device; and
control at least one of the N second electronic devices to play the first content according to a
preset projection strategy.
23.
16-07-2025 - Page 7
An electronic device, comprising:
A touch screen, comprising a touch sensor and a display screen;
one or more processors;
Communication interface;
Memory;
Wherein, one or more computer programs are stored in the memory, and the one or more
computer programs include instructions. When the instructions are executed by the
electronic device, the electronic device executes the cross-device content projection method
as described in any one of claims 1-11 or claims 12-20.
24.
A computer-readable storage medium having instructions stored therein, characterized in
that when the instructions are executed on an electronic device, the electronic device
executes the cross-device content projection method as described in any one of claims 1-11
or claims 12-20.
25.
A computer program product comprising instructions, characterized in that when the
computer program product is run on an electronic device, the electronic device executes the
cross-device content projection method as described in any one of claims 1-11 or claims 12-
20.
